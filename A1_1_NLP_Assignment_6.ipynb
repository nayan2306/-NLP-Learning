{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WB3kWLk_Kl-f",
        "outputId": "1f31de38-81f3-42fc-a0f4-30bee46c85dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.parse import ShiftReduceParser, RecursiveDescentParser\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Define the lexicon and grammar\n",
        "lexicon = {\n",
        "    'The': 'Det',\n",
        "    'cat': 'N',\n",
        "    'sat': 'V',\n",
        "    'on': 'P',\n",
        "    'the': 'Det',\n",
        "    'mat': 'N',\n",
        "}\n",
        "grammar = nltk.CFG.fromstring(\"\"\"\n",
        "    S -> NP VP\n",
        "    NP -> Det N\n",
        "    VP -> V NP | V PP\n",
        "    PP -> P NP\n",
        "    Det -> 'The' | 'the'\n",
        "    N -> 'cat' | 'mat'\n",
        "    V -> 'sat'\n",
        "    P -> 'on'\n",
        "\"\"\")\n",
        "\n",
        "# Tokenize the sentence\n",
        "sentence = \"The cat sat on the mat\"\n",
        "tokens = word_tokenize(sentence)\n",
        "\n",
        "# Use ShiftReduceParser to parse the sentence\n",
        "sr_parser = ShiftReduceParser(grammar)\n",
        "sr_trees = list(sr_parser.parse(tokens))\n",
        "print(\"Shift-Reduce Trees:\")\n",
        "for tree in sr_trees:\n",
        "    print(tree)\n",
        "\n",
        "# Use RecursiveDescentParser to parse the sentence\n",
        "rd_parser = RecursiveDescentParser(grammar)\n",
        "rd_trees = list(rd_parser.parse(tokens))\n",
        "print(\"Recursive Descent Trees:\")\n",
        "for tree in rd_trees:\n",
        "    print(tree)\n"
      ],
      "metadata": {
        "id": "ILzIkw6AlWNf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "62a60a07-7d51-4b36-9ef1-1beb6ce252e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shift-Reduce Trees:\n",
            "(S\n",
            "  (NP (Det The) (N cat))\n",
            "  (VP (V sat) (PP (P on) (NP (Det the) (N mat)))))\n",
            "Recursive Descent Trees:\n",
            "(S\n",
            "  (NP (Det The) (N cat))\n",
            "  (VP (V sat) (PP (P on) (NP (Det the) (N mat)))))\n"
          ]
        }
      ]
    }
  ]
}